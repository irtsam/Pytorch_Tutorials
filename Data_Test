#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Apr  7 15:11:13 2018

@author: ighazi
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Mar 26 15:15:41 2018

@author: ighazi
"""
import torch
import torch.nn as nn
import torch.nn.functional as f
import numpy as np
import torch.optim as optim
from torch.autograd import Variable
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import time




# functions to show an image


def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))


# get some random training images



"""This code is for creating a convolutional neural network classifier that 
will work with MNIST to classify our images"""

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        """The following are the two convolutional layers and the first one 
        comprises of 1 input channel i.e. the images, 6 output channel and 
        convolutional kernel of sie 5"""
        self.conv1= nn.Conv2d(3,6,5)
        """Input channels of size 6, output channels of size 16 and kernel of
        size 5"""
        self.conv2= nn.Conv2d(6,16,5)
        
        """Fully connected neural network portion"""
        self.fc1= nn.Linear(16*5*5, 120)
        self.fc2= nn.Linear(120, 84)
        self.fc3= nn.Linear(84, 10)
        
        """Thus our neural network parameters have been defined"""
    def forward(self,x):
        """The x will be the output vector to feed forward the network. we 
        perform the RelU portion and feeding forward based on our input over
        here as well"""
        
        """Below is the feed forward to convolve, apply relu and Max_pool our code"""        
        x= f.max_pool2d(f.relu(self.conv1(x) ), (2,2))
        #print(x)
        """The next convolutional layer again maxpool size is 2*2"""
        x= f.max_pool2d(f.relu(self.conv2(x)),2)
        """Now we flatten our convolved output as a row"""
        #print(x)
        x= x.view(-1, self.num_flat_features(x))
        """The reLU portion actions on the input depending on the object passed
        to it i.e acts both on convolutional objects and linear objects"""
        
        x= f.relu(self.fc1(x))
        #print(x)
        x= f.relu(self.fc2(x))
        #print(x)
        x= self.fc3(x)
        return x
        
    def num_flat_features(self,x):
        size = x.size()[1:]  # all dimensions except the batch dimension
        #print(size)
        num_features = 1
        for s in size:
            num_features *= s
        #print(num_features)
        return num_features

"""Create a neural net object and then feedforward it by using the net(x) 
procedure. This works as function is one of the abstract functions for nn.module
superclass we inherited"""
global x,y

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

print(transform.size())

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=2)
start_time= time.time()
classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')


dataiter = iter(trainloader)
images, labels = dataiter.next()
net = Net()
# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
